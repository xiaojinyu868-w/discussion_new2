# 需求文档: 会议快照 V1 - AI原生组织信息管理工具

## 介绍

本需求文档定义会议快照 V1 版本的功能迭代。产品定位为 **AI原生组织的信息管理工具**，从组织协作场景切入，提供实时会议转写、智能分析、主动推送等能力。

V1 版本在已有的实时转写基础上，增加：
- 上下文文本流存储
- 用户主动触发的 AI 技能
- 模型自动推送信息（每1分钟巡检）
- 自由问答能力

## 已实现功能（MVP）

- **1秒**音频分片上传（前端每1秒读取录音文件增量）
- 前端分片上传 → 后端 ffmpeg 转码 (M4A → PCM 16kHz) → WebSocket 推送通义听悟
- 后端每**5秒**轮询通义听悟获取转写结果、摘要、关键词
- 前端每**4秒**拉取最新结果并展示
- 说话人识别已**禁用**（`diarizationEnabled: false`）
- 技能触发（内心OS、头脑风暴）使用通义听悟 `CustomPrompt` API

---

## 需求

### 需求 1 - 上下文文本流存储

**用户故事：** 作为系统，我需要将所有转写文本持续追加到一个文本流中，作为后续 AI 处理的上下文基础。

#### 验收标准

1. When 通义听悟返回新的转写段落时，the 系统 shall 将该段落追加到当前会话的文本流存储中。
2. When 文本流更新时，the 系统 shall 保留完整的时间戳信息（startTime、endTime）。
3. When 触发任何 AI 技能时，the 系统 shall 将完整文本流作为上下文传入提示词。
4. When 会话结束时，the 系统 shall 持久化保存完整文本流。

---

### 需求 2 - 用户主动触发技能 (Active Skills)

**用户故事：** 作为用户，我希望通过预设按钮一键触发特定的 AI 技能，快速获得针对性的分析结果。

#### 验收标准

##### 2.1 内心 OS（Inner OS）

1. When 用户点击"内心OS"按钮时，the 系统 shall 将当前文本流作为上下文，调用 LLM 识别对话中的潜台词和话外音。
2. When LLM 返回结果时，the 系统 shall 以卡片形式展示在 AI 总结区域。
3. The 系统 shall 使用"洞察力强、略带毒舌"的观察者风格生成内容。

##### 2.2 头脑风暴（Brainstorming）

1. When 用户点击"头脑风暴"按钮时，the 系统 shall 基于当前讨论内容，生成跳跃性的发散建议。
2. The 系统 shall 模拟"乔布斯风格"的创意顾问角色。
3. When 检测到讨论僵局时，the 系统 shall 优先提供突破性建议。

##### 2.3 别再说了（纠偏功能）

1. When 用户点击"别再说了"按钮时，the 系统 shall 分析当前话题是否偏离主题。
2. When 检测到偏题时，the 系统 shall 生成礼貌但坚定的提醒内容。
3. The 系统 shall 充当会议"主持人"角色，引导回归正轨。

---

### 需求 3 - 模型自动推送信息 (Autonomous Push)

**用户故事：** 作为用户，我希望 AI 能每隔一段时间自动分析会议状态，主动推送有价值的信息，无需我手动触发。

#### 验收标准

1. When 会议进行中，the 系统 shall 每隔 1 分钟自动执行一次会议状态巡检。
2. When 巡检执行时，the 系统 shall 将截止目前的所有文本流输入 LLM 进行分析。
3. The 系统 shall 自动执行以下任务：
   - **意图识别**：提取核心关键点，判断会议所处阶段（开场、争论、决策等）
   - **内心 OS**：识别潜在的话外音和潜台词
   - **专家视角**：以乔布斯画像检索逻辑漏洞，主动推送建议
   - **纠偏提醒**：识别团队是否偏离主题，进行实时引导
4. When 自动分析完成时，the 系统 shall 将结果作为新消息推送到对话流中。
5. The 用户 shall 能够开启/关闭自动推送功能。

---

### 需求 4 - 自由问答 (Multimodal QA)

**用户故事：** 作为用户，我希望能随时根据当前会议上下文进行自由提问，获得即时回答。

#### 验收标准

1. When 用户在输入框输入问题并提交时，the 系统 shall 将问题与当前文本流上下文一起发送给 LLM。
2. When LLM 返回回答时，the 系统 shall 将回答作为新消息展示在对话流中。
3. The 系统 shall 支持文本输入方式提问。
4. The 系统 shall 保留问答历史，作为后续对话的上下文。

---

## 技术约束

- 自动推送间隔：1 分钟（可配置）
- 音频分片上传：1 秒（已实现，前端 `useRecorder.ts`）
- 后端轮询间隔：5 秒（已实现，`POLLING_INTERVAL_MS`）
- 前端拉取间隔：4 秒（已实现，`HomeScreen.tsx`）
- LLM：使用通义千问 Qwen3-Max（OpenAI 兼容 API）
- 说话人识别：已禁用（V1 暂不支持）

---

## 附录：Qwen3-Max 模型说明

### 模型信息

| 属性 | 说明 |
|------|------|
| 模型名称 | `qwen3-max` |
| 总参数量 | 超过 1T |
| 预训练数据 | 36T tokens |
| 版本 | Instruct（指令）/ Thinking（推理） |
| 排名 | LMArena 文本排行榜第三，超越 GPT-5-Chat |

### API 调用方式

采用 **OpenAI 兼容模式**，可直接使用 OpenAI SDK：

- **Endpoint**: `https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions`
- **认证**: `Authorization: Bearer <DASHSCOPE_API_KEY>`
- **模型参数**: `model: "qwen3-max"`

### 关键参数

| 参数 | 类型 | 必选 | 说明 |
|------|------|------|------|
| `model` | string | 是 | 模型名称，如 `qwen3-max` |
| `messages` | array | 是 | 对话消息列表 |
| `stream` | boolean | 否 | 是否流式输出，默认 false |
| `temperature` | float | 否 | 采样温度 (0-2)，控制随机性 |
| `top_p` | float | 否 | 核采样概率 (0-1) |
| `max_tokens` | integer | 否 | 最大生成 token 数 |
